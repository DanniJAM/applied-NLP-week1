{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e71f86",
   "metadata": {},
   "source": [
    "# 2) Adverbs: Do Great Writers Avoid Them?\n",
    "\n",
    "**Goal:** Estimate -ly adverb rate and compare across the two texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac061cf",
   "metadata": {},
   "source": [
    "# Setup: Load Texts\n",
    "\n",
    "This notebook needs **Fellowship of the Ring** and **The Return of the King** as input texts.\n",
    "\n",
    "**How to provide the texts:**\n",
    "1. Aquire books through all means necessary\n",
    "\n",
    "2. Place two text files in the \"data\" folder with names:\n",
    "   - `Fellowship.txt`\n",
    "   - `Return.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0842d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39209a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship chars: 948,198 | TheKing chars: 709,796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_texts(local_fellow: str = '..\\\\data\\\\Fellowship.txt',\n",
    "               local_king: str = '..\\\\data\\\\TheKing.txt'):\n",
    "    \"\"\"Load both texts from disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_fellow : str\n",
    "        Path to Fellowship\n",
    "         text file. Defaults to '../data/Fellowship.txt\n",
    "    '.\n",
    "    local_king : str\n",
    "        Path to TheKing text file. Defaults to '../data/TheKing.txt'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, str]\n",
    "        (fellowship_text, theking_text).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If either file is missing.\n",
    "\n",
    "    Extra Notes\n",
    "    -----------\n",
    "    - Using UTF-8 with `errors='ignore'` avoids codec exceptions on\n",
    "      older Project Gutenberg dumps or inconsistent encodings.\n",
    "    \"\"\"\n",
    "    p1, p2 = Path(local_fellow), Path(local_king)\n",
    "\n",
    "    # Fail fast with a clear message if a file is missing\n",
    "    if not p1.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p1}\\n\"\n",
    "            \"→ Please place 'Fellowship.txt at this path or update load_texts(...).\"\n",
    "        )\n",
    "    if not p2.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p2}\\n\"\n",
    "            \"→ Please place 'TheKing.txt' at this path or update load_texts(...).\"\n",
    "        )\n",
    "\n",
    "    # Read the files (UTF-8; ignore undecodable bytes to stay robust)\n",
    "    fellowship   = p1.read_text(encoding='utf-8', errors='ignore')\n",
    "    theking = p2.read_text(encoding='utf-8', errors='ignore')\n",
    "    return fellowship, theking\n",
    "\n",
    "def normalize(text: str, is_fellowship: bool = False) -> str:\n",
    "    \"\"\"Normalize a text for tokenization.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    \n",
    "    # If it's Fellowship, skip the Foreword and Prologue\n",
    "    if is_fellowship:\n",
    "        prologue_end = text.find('Chapter 1\\n\\nA Long-expected Party')\n",
    "        if prologue_end != -1:\n",
    "            text = text[prologue_end:]\n",
    "    \n",
    "    # For Return of the King\n",
    "    if not is_fellowship:\n",
    "        contents_end = text.find('Book V\\n\\nChapter 1. Minas Tirith')\n",
    "        if contents_end != -1:\n",
    "            text = text[contents_end:]\n",
    "\n",
    "    return text.replace('\\r\\n', '\\n')\n",
    "\n",
    "# Load raw texts\n",
    "fellowship_raw, theking_raw = load_texts()\n",
    "\n",
    "# Normalize for tokenization\n",
    "fellowship = normalize(fellowship_raw, is_fellowship=True)\n",
    "theking = normalize(theking_raw, is_fellowship=False) # Use new file var\n",
    "\n",
    "print(f\"Fellowship chars: {len(fellowship):,} | TheKing chars: {len(theking):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff49ca0",
   "metadata": {},
   "source": [
    "### Helpers: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94529ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship words: 179,144 | TheKing words: 136,735\n",
      "Fellowship sentences: 10,880 | TheKing sentences: 7,449\n"
     ]
    }
   ],
   "source": [
    "# This new regex finds words like \"don't\" but skips junk like \"'s\"\n",
    "WORD_RE = re.compile(r\"\\b[A-Za-z][A-Za-z']*\\b\") \n",
    "\n",
    "def words(text: str):\n",
    "    \"\"\"Smarter word tokenizer (lowercased, ASCII letters + internal apostrophes).\"\"\"\n",
    "    return WORD_RE.findall(text.lower())\n",
    "\n",
    "\n",
    "def sentences(text: str):\n",
    "    \"\"\"Naive sentence splitter using punctuation boundaries.\"\"\"\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text) if s.strip()]\n",
    "\n",
    "\n",
    "# --- Run the tokenizers ---\n",
    "fellowship_words = words(fellowship)\n",
    "theking_words = words(theking)\n",
    "\n",
    "fellowship_sentences = sentences(fellowship)\n",
    "theking_sentences = sentences(theking)\n",
    "\n",
    "# Save total word counts for later\n",
    "nF = len(fellowship_words) # Total words in Fellowship\n",
    "nR = len(theking_words) # Total words in TheKing\n",
    "\n",
    "print(f\"Fellowship words: {nF:,} | TheKing words: {nR:,}\")\n",
    "print(f\"Fellowship sentences: {len(fellowship_sentences):,} | TheKing sentences: {len(theking_sentences):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa5a75",
   "metadata": {},
   "source": [
    "### Estimate -ly Adverb Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ded3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship: 2078/179144 = 1.16%\n",
      "TheKing: 1113/136735 = 0.81%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def adverb_rate(words):\n",
    "    adverbs = [w for w in words if w.endswith('ly') and len(w)>2]\n",
    "    return len(adverbs), len(words), (len(adverbs)/len(words))*100\n",
    "\n",
    "f_adv, f_total, f_pct = adverb_rate(fellowship_words)\n",
    "r_adv, r_total, r_pct = adverb_rate(theking_words)\n",
    "print(f\"Fellowship: {f_adv}/{f_total} = {f_pct:.2f}%\")\n",
    "print(f\"TheKing: {r_adv}/{r_total} = {r_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d6645",
   "metadata": {},
   "source": [
    "**Prompt:** Inspect a sample of detected -ly words. Which are true adverbs vs. adjectives/nouns? How would you refine the rule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "847682d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship adverbs (first 20): ['shortly', 'popularly', 'apparently', 'reputedly', 'finally', 'comfortably', 'lively', 'only', 'suddenly', 'commonly', 'mainly', 'friendly', 'constantly', 'especially', 'seemingly', 'family', 'only', 'suddenly', 'mostly', 'firmly']\n"
     ]
    }
   ],
   "source": [
    "# Show some adverbs from fellowship\n",
    "adverbs_fellowship = [w for w in fellowship_words if w.endswith('ly') and len(w)>2]\n",
    "print(f\"Fellowship adverbs (first 20): {adverbs_fellowship[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338c94f",
   "metadata": {},
   "source": [
    "Let's use a smarter way to find adverbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1160296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    download(\"en_core_web_sm\")          # downloads the small English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  # try again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae9ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running spaCy analysis on Fellowship...\n",
      "Running spaCy analysis on TheKing...\n",
      "\n",
      "--- Final spaCy-powered Adverb Rate ---\n",
      "Fellowship spaCy rate: 102.54/10k\n",
      "TheKing spaCy rate: 72.55/10k\n"
     ]
    }
   ],
   "source": [
    "def strip_gutenberg_markup(t: str) -> str:\n",
    "    # remove lone underscores and _italic_ markup\n",
    "    t = re.sub(r\"\\b_+\\b\", \" \", t)\n",
    "    t = re.sub(r\"_([A-Za-z]+)_\", r\"\\1\", t)\n",
    "    return t\n",
    "\n",
    "# This helper function is from Notebook 1\n",
    "def per_10k(count: int, total_words: int) -> float:\n",
    "    \"\"\"Normalize a raw count per 10,000 words for fair comparisons.\"\"\"\n",
    "    return (count / max(1, total_words)) * 10000.0\n",
    "\n",
    "# 1) Pre-clean both texts\n",
    "fellowship_clean = strip_gutenberg_markup(fellowship)\n",
    "theking_clean = strip_gutenberg_markup(theking)\n",
    "\n",
    "# 2) Process both texts with nlp()\n",
    "#    This may take 1-2 minutes\n",
    "print(\"Running spaCy analysis on Fellowship...\")\n",
    "f_doc = nlp(fellowship_clean)\n",
    "print(\"Running spaCy analysis on TheKing...\")\n",
    "r_doc = nlp(theking_clean)\n",
    "\n",
    "# 3) Count adverbs (POS tag == 'ADV') that end in '-ly'\n",
    "f_adv_spacy = len([t for t in f_doc if t.pos_ == 'ADV' and t.text.endswith('ly')])\n",
    "r_adv_spacy = len([t for t in r_doc if t.pos_ == 'ADV' and t.text.endswith('ly')])\n",
    "\n",
    "# 4) Get rates per 10,000 words (using nF and nR from Cell 8)\n",
    "f_adv_rate_spacy = per_10k(f_adv_spacy, nF)\n",
    "r_adv_rate_spacy = per_10k(r_adv_spacy, nR)\n",
    "\n",
    "print(\"\\n--- Final spaCy-powered Adverb Rate ---\")\n",
    "print(f\"Fellowship spaCy rate: {f_adv_rate_spacy:5.2f}/10k\")\n",
    "print(f\"TheKing spaCy rate: {r_adv_rate_spacy:5.2f}/10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b2c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to 'adverb_rate_chart.json'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57.vega-embed details,\n",
       "  #altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e8d390ac8e9440fa8f4746cc1ffbad57\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-81929291cfcb0b5c9356ec6c05a334e3\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Book\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Book\", \"type\": \"nominal\"}, {\"field\": \"Rate (per 10k words)\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Book\", \"sort\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"Rate (per 10k words)\", \"title\": \"-ly Adverb Rate (per 10k words)\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Stylistic Fingerprint (Tone): Adverb Rate in Tolkien\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-81929291cfcb0b5c9356ec6c05a334e3\": [{\"Book\": \"Fellowship\", \"Rate (per 10k words)\": 102.54320546599382}, {\"Book\": \"The King\", \"Rate (per 10k words)\": 72.54909130800453}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Create a DataFrame for the graph\n",
    "data = [\n",
    "    {'Book': 'Fellowship', 'Rate (per 10k words)': f_adv_rate_spacy},\n",
    "    {'Book': 'The King', 'Rate (per 10k words)': r_adv_rate_spacy}\n",
    "]\n",
    "chart_df = pd.DataFrame(data)\n",
    "\n",
    "# Build the chart\n",
    "chart = alt.Chart(chart_df).mark_bar().encode(\n",
    "    x=alt.X('Book', sort=None),  # Use sort=None to keep the order\n",
    "    y=alt.Y('Rate (per 10k words)', title='-ly Adverb Rate (per 10k words)'),\n",
    "    color='Book',\n",
    "    tooltip=['Book', 'Rate (per 10k words)']\n",
    ").properties(\n",
    "    title='Stylistic Fingerprint (Tone): Adverb Rate in Tolkien'\n",
    ").interactive()\n",
    "\n",
    "# Save the chart\n",
    "chart.save('adverb_rate_chart.json')\n",
    "print(\"Graph saved to 'adverb_rate_chart.json'\")\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
