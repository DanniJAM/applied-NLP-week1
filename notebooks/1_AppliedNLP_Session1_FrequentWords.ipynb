{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a05e673",
   "metadata": {},
   "source": [
    "\n",
    "# 1) Frequent Words = Literary Fingerprints\n",
    "\n",
    "This notebook compares **word frequency** between our two toy texts:\n",
    "- *The Fellowship of the Ring* (here referenced as **Fellowship**)\n",
    "- *The Return of the King* (here referenced as **TheKing**)\n",
    "\n",
    "We practice simple tokenization and frequency analysis, then discuss\n",
    "what's **meaningful signal** vs. **noise** in the results, and how to\n",
    "improve the method (normalization, keyness, etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d25e38",
   "metadata": {},
   "source": [
    "# Setup: Load Texts\n",
    "\n",
    "This notebook needs **The Fellowship of the Ring** and **The Return of the King** as input texts.\n",
    "\n",
    "**How to provide the texts:**\n",
    "\n",
    "1. Download the following books as `.txt` files:\n",
    "\n",
    "   \n",
    "\n",
    "2. Place two text files in the \"data\" folder with names:\n",
    "   - `Fellowship.txt`  (The Fellowship of the Ring)\n",
    "   - `TheKing.txt` (The Return of the King)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2f5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5da6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts(local_fellowship: str = '..\\\\data\\\\Fellowship.txt',\n",
    "               local_return: str = '..\\\\data\\\\TheKing.txt'):\n",
    "    \"\"\"Load Fellowship and Return of the King texts from disk.\"\"\"\n",
    "    \n",
    "    p1, p2 = Path(local_fellowship), Path(local_return)\n",
    "\n",
    "    # Fail fast with a clear message if a file is missing\n",
    "    if not p1.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p1}\\n\"\n",
    "            \"→ Please make sure 'Fellowship.txt' is in the 'data' folder.\"\n",
    "        )\n",
    "    if not p2.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p2}\\n\"\n",
    "            \"→ Please make sure 'TheKing.txt' is in the 'data' folder.\"\n",
    "        )\n",
    "\n",
    "    # Read the files\n",
    "    fellowship_text = p1.read_text(encoding='utf-8', errors='ignore')\n",
    "    return_text = p2.read_text(encoding='utf-8', errors='ignore')\n",
    "    return fellowship_text, return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd6cf535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text: str, is_fellowship: bool = False) -> str:\n",
    "    \"\"\"Normalize a text for tokenization.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    \n",
    "    # If it's Fellowship, skip the Foreword and Prologue\n",
    "    if is_fellowship:\n",
    "        prologue_end = text.find('Chapter 1\\n\\nA Long-expected Party')\n",
    "        if prologue_end != -1:\n",
    "            text = text[prologue_end:]\n",
    "    \n",
    "    # For Return of the King\n",
    "    if not is_fellowship:\n",
    "        contents_end = text.find('Book V\\n\\nChapter 1. Minas Tirith')\n",
    "        if contents_end != -1:\n",
    "            text = text[contents_end:]\n",
    "\n",
    "    return text.replace('\\r\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7b9560d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fellowship' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [s.strip() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(?<=[.!?])\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+\u001b[39m\u001b[33m'\u001b[39m, text) \u001b[38;5;28;01mif\u001b[39;00m s.strip()]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# --- Run the tokenizers ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m fellowship_words = words(\u001b[43mfellowship\u001b[49m)\n\u001b[32m     16\u001b[39m return_king_words = words(return_king)\n\u001b[32m     18\u001b[39m fellowship_sentences = sentences(fellowship)\n",
      "\u001b[31mNameError\u001b[39m: name 'fellowship' is not defined"
     ]
    }
   ],
   "source": [
    "# This new regex finds words like \"don't\" but skips junk like \"'s\"\n",
    "WORD_RE = re.compile(r\"\\b[A-Za-z][A-Za-z']*\\b\") \n",
    "\n",
    "def words(text: str):\n",
    "    \"\"\"Smarter word tokenizer (lowercased, ASCII letters + internal apostrophes).\"\"\"\n",
    "    return WORD_RE.findall(text.lower())\n",
    "\n",
    "\n",
    "def sentences(text: str):\n",
    "    \"\"\"Naive sentence splitter using punctuation boundaries.\"\"\"\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text) if s.strip()]\n",
    "\n",
    "\n",
    "# --- Run the tokenizers ---\n",
    "fellowship_words = words(fellowship)\n",
    "return_king_words = words(return_king)\n",
    "\n",
    "fellowship_sentences = sentences(fellowship)\n",
    "return_king_sentences = sentences(return_king)\n",
    "\n",
    "# Save total word counts for later\n",
    "nF = len(fellowship_words) # Total words in Fellowship\n",
    "nR = len(return_king_words) # Total words in TheKing\n",
    "\n",
    "print(f\"Fellowship words: {nF:,} | TheKing words: {nR:,}\")\n",
    "print(f\"Fellowship sentences: {len(fellowship_sentences):,} | TheKing sentences: {len(return_king_sentences):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64e2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(words_list, min_len=4, extra_stop=None, n=30):\n",
    "    \"\"\"Return top-N frequent words after lightweight filtering.\"\"\"\n",
    "    base_stop = {\n",
    "        'the','and','to','of','a','i','it','in','that','was','he','you','is','for','on','as',\n",
    "        'with','his','her','at','be','she','had','not','but','said','they','them','this','so','all','one','very',\n",
    "        'there','what','were','from','have','would','could','when','been','their','we','my','me','or','by','up','no','out','if',\n",
    "        \n",
    "        # --- CUSTOM TOLKIEN STOPWORDS (must be lowercase) ---\n",
    "        'frodo', 'sam', 'pippin', 'merry', 'gandalf', 'aragorn', 'boromir', 'gimli', 'legolas', 'then', 'bilbo', 'samwise'\n",
    "    }\n",
    "    if extra_stop:\n",
    "        base_stop |= set(extra_stop)\n",
    "\n",
    "    c = Counter(w for w in words_list if len(w) >= min_len and w not in base_stop)\n",
    "    return c.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d178945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_10k(count: int, total_words: int) -> float:\n",
    "    \"\"\"Normalize a raw count per 10,000 words for fair comparisons.\"\"\"\n",
    "    return (count / max(1, total_words)) * 10000.0\n",
    "\n",
    "\n",
    "def log_likelihood(k1: int, n1: int, k2: int, n2: int) -> float:\n",
    "    \"\"\"Dunning’s log-likelihood (G^2) keyness score for word distinctiveness.\"\"\"\n",
    "    E1 = n1 * (k1 + k2) / max(1, (n1 + n2))\n",
    "    E2 = n2 * (k1 + k2) / max(1, (n1 + n2))\n",
    "\n",
    "    def term(k, E):\n",
    "        return 0.0 if k == 0 or E == 0 else k * math.log(k / E)\n",
    "\n",
    "    return 2.0 * (term(k1, E1) + term(k2, E2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c7d96",
   "metadata": {},
   "source": [
    "\n",
    "## Load & Normalize\n",
    "We load both texts using **inline path checks** and then apply a simple normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcbfb253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship chars: 948,198 | Return of the King chars: 709,796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load raw texts\n",
    "fellowship_raw, return_raw = load_texts()\n",
    "\n",
    "# Normalize for tokenization\n",
    "# We pass is_fellowship=True to tell our new function to skip the prologue\n",
    "fellowship   = normalize(fellowship_raw, is_fellowship=True)\n",
    "return_king = normalize(return_raw) \n",
    "\n",
    "# Update the print labels\n",
    "print(f\"Fellowship chars: {len(fellowship):,} | Return of the King chars: {len(return_king):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b194521",
   "metadata": {},
   "source": [
    "\n",
    "## Tokenize\n",
    "We use a simple regex tokenizer (letters + apostrophes). For more serious work,\n",
    "consider spaCy or stanza for tagging and lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a843aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellowship words: 179,144 | Return of the King words: 136,735\n",
      "Fellowship sentences: 10,880 | Return of the King sentences: 7,449\n"
     ]
    }
   ],
   "source": [
    "# --- Run the tokenizers ---\n",
    "fellowship_words = words(fellowship)\n",
    "return_king_words = words(return_king)\n",
    "\n",
    "fellowship_sentences = sentences(fellowship)\n",
    "return_king_sentences = sentences(return_king)\n",
    "\n",
    "print(f\"Fellowship words: {len(fellowship_words):,} | Return of the King words: {len(return_king_words):,}\")\n",
    "print(f\"Fellowship sentences: {len(fellowship_sentences):,} | Return of the King sentences: {len(return_king_sentences):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188dd619",
   "metadata": {},
   "source": [
    "\n",
    "## Top Words (after basic stopwords)\n",
    "The list is **partly signal, partly noise**—use it to start discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec91f70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Fellowship: [('will', 559), ('into', 449), ('long', 421), ('came', 421), ('down', 418), ('again', 412), ('like', 403), ('more', 388), ('before', 378), ('come', 377), ('your', 347), ('some', 346), ('great', 335), ('back', 334), ('many', 334)]\n",
      "Top Return of the King: [('will', 588), ('came', 455), ('great', 443), ('come', 388), ('your', 335), ('more', 331), ('like', 302), ('down', 299), ('into', 293), ('before', 291), ('upon', 289), ('long', 281), ('some', 275), ('again', 272), ('still', 269)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Fellowship:\", top_words(fellowship_words, n=15))\n",
    "print(\"Top Return of the King:\", top_words(return_king_words, n=15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d4fbd",
   "metadata": {},
   "source": [
    "## Optional continution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825a8f8",
   "metadata": {},
   "source": [
    "\n",
    "## Distinctiveness via Log-Likelihood (Keyness)\n",
    "Raw frequency is not enough. Compute **G²** to find words that are *distinctive* of each book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "285caabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_10k(count: int, total_words: int) -> float:\n",
    "    \"\"\"Normalize a raw count per 10,000 words for fair comparisons.\"\"\"\n",
    "    return (count / max(1, total_words)) * 10000.0\n",
    "\n",
    "\n",
    "def lolookingglass_likelihood(k1: int, n1: int, k2: int, n2: int) -> float:\n",
    "    \"\"\"Dunning’s log-likelihood (G^2) keyness score for word distinctiveness.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1 : int  Frequency in corpus A\n",
    "    n1 : int  Total words in corpus A\n",
    "    k2 : int  Frequency in corpus B\n",
    "    n2 : int  Total words in corpus B\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        G^2 value; larger absolute values indicate stronger distinctiveness.\n",
    "        Direction should be interpreted by comparing rates (per_10k) or counts.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Symmetric measure widely used for corpus comparison.\n",
    "    - Great classroom upgrade over raw frequency lists.\n",
    "    \"\"\"\n",
    "    E1 = n1 * (k1 + k2) / max(1, (n1 + n2))\n",
    "    E2 = n2 * (k1 + k2) / max(1, (n1 + n2))\n",
    "\n",
    "    def term(k, E):\n",
    "        return 0.0 if k == 0 or E == 0 else k * math.log(k / E)\n",
    "\n",
    "    return 2.0 * (term(k1, E1) + term(k2, E2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d91d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20 Most Distinctive Words (Log-Likelihood) ---\n",
      "        WORD  G2_SCORE   FELLOWSHIP_RATE   RETURN_RATE\n",
      "----------------------------------------------------\n",
      "           s     983.1              0.45         46.29  (More in Return of the King)\n",
      "           t     499.0              0.00         21.79  (More in Return of the King)\n",
      "     faramir     271.3              0.00         11.85  (More in Return of the King)\n",
      "        king     266.8              1.34         17.48  (More in Return of the King)\n",
      "       don't     239.3             11.78          0.00  (More in Fellowship)\n",
      "          ll     217.7              0.00          9.51  (More in Return of the King)\n",
      "         men     203.6              6.25         25.74  (More in Return of the King)\n",
      "        city     199.4              1.17         13.60  (More in Return of the King)\n",
      "         don     165.8              0.00          7.24  (More in Return of the King)\n",
      "        lord     164.0              3.41         17.33  (More in Return of the King)\n",
      "    denethor     161.1              0.33          8.85  (More in Return of the King)\n",
      "          ve     151.8              0.17          7.68  (More in Return of the King)\n",
      "     strider     149.7             11.11          0.95  (More in Fellowship)\n",
      "    beregond     122.2              0.00          5.34  (More in Return of the King)\n",
      "      gondor     120.8              1.79         11.12  (More in Return of the King)\n",
      "       elves     108.3              9.55          1.24  (More in Fellowship)\n",
      "         and     106.7            400.13        477.64  (More in Return of the King)\n",
      "      battle     102.4              0.61          7.02  (More in Return of the King)\n",
      "          re      98.0              0.11          4.97  (More in Return of the King)\n",
      "         tom      93.7              6.70          0.51  (More in Fellowship)\n"
     ]
    }
   ],
   "source": [
    "# Build frequency dictionaries\n",
    "cf = Counter(fellowship_words)\n",
    "cr = Counter(return_king_words)\n",
    "nF, nR = sum(cf.values()), sum(cr.values())\n",
    "\n",
    "# Compare a candidate set (union of top ~500 from each to keep it fast)\n",
    "candidates = set([w for w,_ in cf.most_common(500)] + [w for w,_ in cr.most_common(500)])\n",
    "\n",
    "rows = []\n",
    "for w in candidates:\n",
    "    # (filter out any remaining stopwords that slipped through)\n",
    "    if w in {'frodo', 'sam', 'pippin', 'merry', 'gandalf', 'aragorn', 'boromir', 'gimli', 'legolas', 'then', 'bilbo', 'samwise'}:\n",
    "        continue\n",
    "    \n",
    "    # This line is now corrected (per_10k instead of per_1ci0k)\n",
    "    g2 = log_likelihood(cf[w], nF, cr[w], nR)\n",
    "    rows.append((g2, w, per_10k(cf[w], nF), per_10k(cr[w], nR)))\n",
    "\n",
    "# Sort by distinctiveness (descending)\n",
    "rows.sort(reverse=True)\n",
    "\n",
    "print(\"--- 20 Most Distinctive Words (Log-Likelihood) ---\")\n",
    "print(f\"{'WORD':>12}  {'G2_SCORE':>8}  {'FELLOWSHIP_RATE':>16}  {'RETURN_RATE':>12}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "for g2, w, f10k, r10k in rows[:20]:\n",
    "    # We check which rate is higher to label the \"direction\"\n",
    "    if f10k > r10k:\n",
    "        print(f\"{w:>12}  {g2:8.1f}  {f10k:16.2f}  {r10k:12.2f}  (More in Fellowship)\")\n",
    "    else:\n",
    "        print(f\"{w:>12}  {g2:8.1f}  {f10k:16.2f}  {r10k:12.2f}  (More in Return of the King)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dac13755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Character & Pronoun Focus Analysis ---\n",
      "Graph saved to 'combined_character_focus_chart.json'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7ee3a306d9104c8d935e19da7166ff2f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7ee3a306d9104c8d935e19da7166ff2f.vega-embed details,\n",
       "  #altair-viz-7ee3a306d9104c8d935e19da7166ff2f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7ee3a306d9104c8d935e19da7166ff2f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7ee3a306d9104c8d935e19da7166ff2f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7ee3a306d9104c8d935e19da7166ff2f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d34968060ecb04ed35cab0ef179b2c8b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Book\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Term\", \"header\": {\"labelOrient\": \"bottom\", \"titleOrient\": \"bottom\"}, \"sort\": [\"he/him\", \"she/her\", \"gandalf\", \"aragorn\", \"frodo\", \"sam\", \"boromir\", \"bilbo\", \"faramir\", \"denethor\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Book\", \"type\": \"nominal\"}, {\"field\": \"Term\", \"type\": \"nominal\"}, {\"field\": \"Rate (per 10k words)\", \"format\": \".2f\", \"type\": \"quantitative\"}], \"x\": {\"axis\": null, \"field\": \"Book\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Rate (per 10k words)\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_3\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Combined Character & Pronoun Focus: Fellowship vs. TheKing\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-d34968060ecb04ed35cab0ef179b2c8b\": [{\"Book\": \"Fellowship\", \"Term\": \"he/him\", \"Rate (per 10k words)\": 207.37507256732013}, {\"Book\": \"TheKing\", \"Term\": \"he/him\", \"Rate (per 10k words)\": 227.95919113613925}, {\"Book\": \"Fellowship\", \"Term\": \"she/her\", \"Rate (per 10k words)\": 17.86272495869245}, {\"Book\": \"TheKing\", \"Term\": \"she/her\", \"Rate (per 10k words)\": 26.474567594251653}, {\"Book\": \"Fellowship\", \"Term\": \"gandalf\", \"Rate (per 10k words)\": 24.728709864689858}, {\"Book\": \"TheKing\", \"Term\": \"gandalf\", \"Rate (per 10k words)\": 22.3790543752514}, {\"Book\": \"Fellowship\", \"Term\": \"aragorn\", \"Rate (per 10k words)\": 11.16420309918278}, {\"Book\": \"TheKing\", \"Term\": \"aragorn\", \"Rate (per 10k words)\": 16.45518704062603}, {\"Book\": \"Fellowship\", \"Term\": \"frodo\", \"Rate (per 10k words)\": 57.38400392979949}, {\"Book\": \"TheKing\", \"Term\": \"frodo\", \"Rate (per 10k words)\": 28.59545836837679}, {\"Book\": \"Fellowship\", \"Term\": \"sam\", \"Rate (per 10k words)\": 22.105122136381905}, {\"Book\": \"TheKing\", \"Term\": \"sam\", \"Rate (per 10k words)\": 33.714849892127106}, {\"Book\": \"Fellowship\", \"Term\": \"boromir\", \"Rate (per 10k words)\": 8.261510293395258}, {\"Book\": \"TheKing\", \"Term\": \"boromir\", \"Rate (per 10k words)\": 1.9746224448751235}, {\"Book\": \"Fellowship\", \"Term\": \"bilbo\", \"Rate (per 10k words)\": 13.508685750011164}, {\"Book\": \"TheKing\", \"Term\": \"bilbo\", \"Rate (per 10k words)\": 2.413427432625151}, {\"Book\": \"Fellowship\", \"Term\": \"faramir\", \"Rate (per 10k words)\": 0.0}, {\"Book\": \"TheKing\", \"Term\": \"faramir\", \"Rate (per 10k words)\": 11.84773466925074}, {\"Book\": \"Fellowship\", \"Term\": \"denethor\", \"Rate (per 10k words)\": 0.33492609297548337}, {\"Book\": \"TheKing\", \"Term\": \"denethor\", \"Rate (per 10k words)\": 8.849233919625553}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "print(\"\\n--- Combined Character & Pronoun Focus Analysis ---\")\n",
    "\n",
    "# 1. Define all the terms you want to track in the graph\n",
    "# We'll create \"pseudo-words\" for the pronoun groups\n",
    "target_terms = [\n",
    "    'he/him', \n",
    "    'she/her', \n",
    "    'gandalf', \n",
    "    'aragorn', \n",
    "    'frodo', \n",
    "    'sam',\n",
    "    'boromir', \n",
    "    'bilbo',\n",
    "    'faramir',\n",
    "    'denethor'\n",
    "]\n",
    "\n",
    "# 2. Get the counts and rates for each term\n",
    "combined_data = []\n",
    "\n",
    "for term in target_terms:\n",
    "    fellowship_count = 0\n",
    "    return_count = 0\n",
    "    \n",
    "    # Handle the special pronoun groups\n",
    "    if term == 'he/him':\n",
    "        fellowship_count = cf['he'] + cf['him']\n",
    "        return_count = cr['he'] + cr['him']\n",
    "    elif term == 'she/her':\n",
    "        fellowship_count = cf['she'] + cf['her']\n",
    "        return_count = cr['she'] + cr['her']\n",
    "    # Handle regular names\n",
    "    else:\n",
    "        fellowship_count = cf[term]\n",
    "        return_count = cr[term]\n",
    "        \n",
    "    # Add data for Fellowship\n",
    "    combined_data.append({\n",
    "        'Book': 'Fellowship',\n",
    "        'Term': term,\n",
    "        'Rate (per 10k words)': per_10k(fellowship_count, nF)\n",
    "    })\n",
    "    \n",
    "    # Add data for TheKing\n",
    "    combined_data.append({\n",
    "        'Book': 'TheKing',\n",
    "        'Term': term,\n",
    "        'Rate (per 10k words)': per_10k(return_count, nR)\n",
    "    })\n",
    "\n",
    "# 3. Create a DataFrame\n",
    "chart_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# 4. Build the Grouped Bar Chart\n",
    "chart = alt.Chart(chart_df).mark_bar().encode(\n",
    "    # Set the x-axis to the Book name\n",
    "    x=alt.X('Book', axis=None), # axis=None hides the \"Fellowship/TheKing\" label under each bar\n",
    "    \n",
    "    # Set the y-axis to the normalized rate\n",
    "    y=alt.Y('Rate (per 10k words)'),\n",
    "    \n",
    "    # Color the bars based on the Book\n",
    "    color='Book',\n",
    "    \n",
    "    # Create grouped columns, one for each \"Term\"\n",
    "    column=alt.Column('Term', sort=target_terms, header=alt.Header(titleOrient=\"bottom\", labelOrient=\"bottom\")),\n",
    "    \n",
    "    tooltip=['Book', 'Term', alt.Tooltip('Rate (per 10k words)', format='.2f')]\n",
    ").properties(\n",
    "    title='Combined Character & Pronoun Focus: Fellowship vs. TheKing'\n",
    ").interactive()\n",
    "\n",
    "# 5. Save and Display the Chart\n",
    "chart.save('combined_character_focus_chart.json')\n",
    "print(\"Graph saved to 'combined_character_focus_chart.json'\")\n",
    "\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
